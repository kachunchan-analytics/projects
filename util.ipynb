{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat\n",
    "\n",
    "def parse_ipynb(ipynb_path):\n",
    "    \"\"\"\n",
    "    Parses a Jupyter Notebook (.ipynb) file and extracts code and markdown cells.\n",
    "\n",
    "    Args:\n",
    "        ipynb_path: The path to the .ipynb file.\n",
    "\n",
    "    Returns:\n",
    "        A dictionary with lists 'code' (Python code blocks) and 'markdown' (Markdown cells).\n",
    "        Returns None if an error occurs (file not found, parsing error, etc.).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(ipynb_path, 'r', encoding='utf-8') as f:  # Specify UTF-8 encoding for broader compatibility\n",
    "            nb = nbformat.read(f, as_version=4) # Read and ensure version 4\n",
    "\n",
    "        code_cells = []\n",
    "        markdown_cells = []\n",
    "        raw_cells = [] #Added to capture cells that are neither code nor markdown\n",
    "\n",
    "        for cell in nb.cells:\n",
    "            if cell.cell_type == \"code\":\n",
    "                code_cells.append(cell.source)\n",
    "            elif cell.cell_type == \"markdown\":\n",
    "                markdown_cells.append(cell.source)\n",
    "            else:\n",
    "                raw_cells.append(cell) #Append other cell types\n",
    "\n",
    "\n",
    "        return {\"code\": code_cells, \"markdown\": markdown_cells, \"raw\": raw_cells}\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at '{ipynb_path}'\")\n",
    "        return None\n",
    "    except nbformat.reader.NotJSONError:\n",
    "        print(f\"Error: Invalid JSON format in '{ipynb_path}'\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "ipynb_file_path = \"ConvolutionalNeuralNetwork_Prediction_toc.ipynb\"  # Replace with your .ipynb file path\n",
    "\n",
    "result = parse_ipynb(ipynb_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['# Table of Contents\\n  - [Install Libraries](#install-libraries)\\n- [Data Downloading](#data-downloading)\\n- [GAF](#gaf)\\n- [Train Test Split](#train-test-split)\\n- [Applying Class Weights](#applying-class-weights)\\n- [Model Training and Evaluation](#model-training-and-evaluation)\\n',\n",
       " '[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1fXhuSLU_CxPIHiMbELwEuuKoJih2SeQs?usp=sharing)',\n",
       " \"## <a id='install-libraries'></a> Install Libraries\",\n",
       " \"## <a id='data-downloading'></a> Data Downloading\",\n",
       " \"We begin by downloading historical stock price data using the yfinance library. We focus on the 'Close' price as our primary time series for analysis.\",\n",
       " \"## <a id='gaf'></a> GAF\\nGramian Angular Field (GAF) is a technique that encodes a time series as a 2D image by representing each data point as a polar coordinate. The radial coordinate is the time point itself, and the angular coordinate is the scaled value of the time series at that point. This transformation allows us to capture the temporal dependencies and relationships within the time series in an image format.\",\n",
       " 'Before feeding the GAF images into the CNN, we need to prepare the corresponding labels. The label for each GAF image represents whether the stock price increased or decreased [window_size] days after the end of the time window represented by that GAF image. A label of 1 indicates an upward movement, and 0 indicates a downward movement.',\n",
       " \"## <a id='train-test-split'></a> Train Test Split\",\n",
       " \"To evaluate the model's ability to generalize to unseen data, we split the prepared data into training and testing sets. The training set is used to train the model, while the testing set is used to assess its performance on data it has not encountered during training.\",\n",
       " \"## <a id='applying-class-weights'></a> Applying Class Weights\",\n",
       " 'In financial time series data, the distribution of upward and downward price movements can often be imbalanced. To address this potential class imbalance, we apply class weights during model training. This gives more importance to the minority class (the class with fewer examples), helping the model learn from both classes effectively.',\n",
       " \"## <a id='model-training-and-evaluation'></a> Model Training and Evaluation\",\n",
       " \"The CNN model is trained using the prepared training data. We monitor the model's performance on the validation data during training and save the model with the best validation accuracy.\"]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['markdown']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate TOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table of Contents added to ConvolutionalNeuralNetwork_Prediction_toc.ipynb\n"
     ]
    }
   ],
   "source": [
    "import nbformat\n",
    "from nbformat.v4 import new_markdown_cell\n",
    "import os\n",
    "import re\n",
    "\n",
    "def generate_toc(nb_path):\n",
    "    \"\"\"\n",
    "    Generates a table of contents for a Jupyter Notebook, adding anchors to headings.\n",
    "\n",
    "    Args:\n",
    "        nb_path: Path to the .ipynb file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(nb_path, 'r') as f:\n",
    "            nb = nbformat.read(f, as_version=4)\n",
    "\n",
    "        toc = \"# Table of Contents\\n\"\n",
    "        level = 0\n",
    "        toc_items = []\n",
    "        heading_anchors = {} # Dictionary to store heading anchors\n",
    "\n",
    "        for i, cell in enumerate(nb.cells):\n",
    "            if cell.cell_type == \"markdown\":\n",
    "                lines = cell.source.splitlines()\n",
    "                for line in lines:\n",
    "                    line = line.strip()\n",
    "                    match = re.match(r\"^#{1,6}\\s*(.*)\", line) # Match headings with 1 to 6 #s\n",
    "                    if match:\n",
    "                        heading_level = len(match.group(0)) - len(match.group(0).lstrip(\"#\"))\n",
    "                        heading_text = match.group(1).strip()\n",
    "                        \n",
    "                        # Create anchor ID (slugify heading text)\n",
    "                        anchor_id = re.sub(r\"[^a-zA-Z0-9]+\", \"-\", heading_text).lower()\n",
    "                        \n",
    "                        # Add anchor to original heading\n",
    "                        modified_line = f\"#{'#' * heading_level} <a id='{anchor_id}'></a> {heading_text}\"\n",
    "                        lines[lines.index(line)] = modified_line\n",
    "                        \n",
    "                        heading_anchors[anchor_id] = i #Store anchor and cell index\n",
    "\n",
    "                        while heading_level > level:\n",
    "                            toc_items.append(\"  \")\n",
    "                            level += 1\n",
    "                        while heading_level < level:\n",
    "                            toc_items.pop()\n",
    "                            level -= 1\n",
    "\n",
    "                        toc_items.append(f\"- [{heading_text}](#{anchor_id})\\n\")\n",
    "\n",
    "                #Update cell source with modified lines\n",
    "                cell.source = \"\\n\".join(lines)\n",
    "\n",
    "        toc += \"\".join(toc_items)\n",
    "        toc_cell = new_markdown_cell(toc)\n",
    "        nb.cells.insert(0, toc_cell)\n",
    "\n",
    "        base, ext = os.path.splitext(nb_path)\n",
    "        new_nb_path = f\"{base}_toc{ext}\"\n",
    "\n",
    "        with open(new_nb_path, 'w') as f:\n",
    "            nbformat.write(nb, f)\n",
    "        print(f\"Table of Contents added to {new_nb_path}\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {nb_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "generate_toc(\"ConvolutionalNeuralNetwork_Prediction.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
